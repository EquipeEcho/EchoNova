ğŸ“ **src/lib/ai/ (NÃºcleo de AbstraÃ§Ã£o da IA)**
â”‚
â”œâ”€â”€ ğŸ“„ **ChatProvider.ts (O Contrato / A Planta Baixa)**
â”‚   â””â”€â”€ ğŸ“ **FunÃ§Ã£o:** Este Ã© o arquivo mais importante para a arquitetura. Ele define um "contrato" que qualquer provedor de IA deve seguir. Ele nÃ£o sabe *como* se comunicar com uma IA, apenas *quais* estruturas de dados e mÃ©todos devem existir.
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ§© **interface IaResponse:** Define um formato de resposta PADRÃƒO. NÃ£o importa se a resposta veio do OpenAI ou do Ollama, ela sempre serÃ¡ convertida para esta estrutura. Isso permite que o resto da sua aplicaÃ§Ã£o (a interface do usuÃ¡rio, por exemplo) espere sempre o mesmo formato de dados.
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ§© **interface HistoryMessage:** Define um formato PADRÃƒO para o histÃ³rico da conversa. Garante que o histÃ³rico seja gerenciado da mesma forma, independentemente do provedor.
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ§© **interface ChatProvider:** Ã‰ o contrato principal. Declara que qualquer classe que se considere um "ChatProvider" DEVE ter um mÃ©todo chamado `sendMessage` que aceita uma mensagem, um histÃ³rico e um prompt inicial, e retorna uma `Promise<IaResponse>`.
â”‚
â”œâ”€â”€ ğŸ“ **ImplementaÃ§Ãµes Concretas (Os Trabalhadores)**
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ **OpenAIProvider.ts**
â”‚   â”‚   â””â”€â”€ ğŸ“ **FunÃ§Ã£o:** Ã‰ a implementaÃ§Ã£o especÃ­fica do "contrato" para se comunicar com a API do OpenAI (ChatGPT).
â”‚   â”‚   â””â”€â”€ ğŸ”— **LigaÃ§Ãµes e LÃ³gica:**
â”‚   â”‚       â”œâ”€â”€ â¡ï¸ **Implementa:** `ChatProvider`. Ele cumpre as regras definidas em `ChatProvider.ts`.
â”‚   â”‚       â”œâ”€â”€ â¬…ï¸ **Depende de:** `ChatProvider.ts` para usar as interfaces `IaResponse` e `HistoryMessage`.
â”‚   â”‚       â””â”€â”€ âš™ï¸ **Como funciona:**
â”‚   â”‚           1. LÃª a chave da API do OpenAI (`OPENAI_API_KEY`).
â”‚   â”‚           2. Usa a API REST do OpenAI para enviar mensagens ao ChatGPT.
â”‚   â”‚           3. Envia a mensagem e o histÃ³rico no formato que a API do OpenAI espera.
â”‚   â”‚           4. Recebe a resposta em texto JSON, a analisa (`JSON.parse`) e a converte para o tipo `IaResponse`.
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“„ **OllamaProvider.ts**
â”‚       â””â”€â”€ ğŸ“ **FunÃ§Ã£o:** Ã‰ a implementaÃ§Ã£o especÃ­fica do "contrato" para se comunicar com um servidor Ollama local ou remoto.
â”‚       â””â”€â”€ ğŸ”— **LigaÃ§Ãµes e LÃ³gica:**
â”‚           â”œâ”€â”€ â¡ï¸ **Implementa:** `ChatProvider`. Ele tambÃ©m obedece Ã s mesmas regras.
â”‚           â”œâ”€â”€ â¬…ï¸ **Depende de:** `ChatProvider.ts` para as interfaces padrÃ£o.
â”‚           â””â”€â”€ âš™ï¸ **Como funciona:**
â”‚               1. LÃª as URLs do servidor Ollama (`OLLAMA_BASE_URL` e `OLLAMA_MODEL_NAME`).
â”‚               2. Usa a funÃ§Ã£o `fetch` para fazer uma requisiÃ§Ã£o HTTP para a API do Ollama.
â”‚               3. **Adapta** o formato do histÃ³rico do padrÃ£o `HistoryMessage` para o formato que a API do Ollama espera (ex: `role: "model"` vira `role: "assistant"`).
â”‚               4. Recebe a resposta, extrai o conteÃºdo JSON e o converte para o tipo `IaResponse`.
â”‚
â””â”€â”€ ğŸ“„ **providerFactory.ts (A FÃ¡brica / O Gerente)**
    â””â”€â”€ ğŸ“ **FunÃ§Ã£o:** Este arquivo atua como uma "fÃ¡brica". Sua Ãºnica responsabilidade Ã© decidir qual provedor de IA deve ser usado, instanciÃ¡-lo e entregÃ¡-lo para quem o solicitou. Isso Ã© crucial para desacoplar o cÃ³digo.
    â””â”€â”€ ğŸ”— **LigaÃ§Ãµes e LÃ³gica:**
        â”œâ”€â”€ â¬…ï¸ **Depende de:** `ChatProvider.ts`, `OpenAIProvider.ts`, e `OllamaProvider.ts`.
        â””â”€â”€ âš™ï¸ **Como funciona:**
            1. LÃª a variÃ¡vel de ambiente `AI_PROVIDER` para saber qual IA a aplicaÃ§Ã£o deve usar.
            2. Usa um `switch` para verificar o valor.
            3. Se for "OLLAMA", cria uma `new OllamaProvider()`.
            4. Se for "OPENAI" (ou qualquer outro valor, por ser o padrÃ£o), cria uma `new OpenAIProvider()`.
            5. Retorna a instÃ¢ncia criada. O importante Ã© que o tipo de retorno da funÃ§Ã£o Ã© `ChatProvider` (a interface), e nÃ£o a classe concreta. O cÃ³digo que chama `getChatProvider()` nÃ£o precisa saber se recebeu um OpenAI ou um Ollama, apenas que o objeto retornado tem um mÃ©todo `sendMessage`.

---

### **Resumo da Arquitetura e Fluxo de Dados:**

1.  **DefiniÃ§Ã£o do PadrÃ£o:** O `ChatProvider.ts` cria um padrÃ£o universal de como a aplicaÃ§Ã£o vai interagir com qualquer IA.
2.  **ImplementaÃ§Ã£o EspecÃ­fica:** `OpenAIProvider.ts` e `OllamaProvider.ts` sÃ£o implementaÃ§Ãµes "plugÃ¡veis". Cada um sabe como "falar" com sua respectiva IA e como "traduzir" a conversa para o padrÃ£o universal.
3.  **SeleÃ§Ã£o DinÃ¢mica:** O `getChatProvider()` funciona como um gerente que lÃª uma configuraÃ§Ã£o (`AI_PROVIDER`) e escolhe qual "trabalhador" (OpenAI ou Ollama) serÃ¡ usado na aplicaÃ§Ã£o.
4.  **Uso Desacoplado:** O resto da sua aplicaÃ§Ã£o simplesmente chama `getChatProvider()` uma vez para obter um provedor e, a partir daÃ­, apenas usa o mÃ©todo `.sendMessage()`, sem se preocupar com os detalhes de qual IA estÃ¡ por trÃ¡s.

Essa arquitetura torna o sistema extremamente **flexÃ­vel**. Se amanhÃ£ vocÃª quiser adicionar suporte para outra IA, basta criar um arquivo novo que siga o mesmo "contrato" e adicionar um `case` no `switch` da fÃ¡brica. Nenhuma outra parte do seu cÃ³digo precisarÃ¡ ser alterada.